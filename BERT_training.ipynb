{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Pre-Training BERT from scratch</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center\">This notebook is part of multilingual codemixed NLP research I did at SSN</h3>\n",
    "<p style=\"text-align:center\">Since there is not much documentation on pre-training BERT so I decided to put it all in one place.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT (Bidirectional Encoder Representation form Transformers) is a state-of-art NLP neural network developed by google and is even used for Google searches. Recurrent Neural Networks (RNN's) were a standard in NLP before transformers but RNN's flawed in multiple ways as they cannot remember long term dependencies, in much more layman terms the words occuring earlier in sentences looses its dependency from a word occuring far later in the sentence a solution to this was ELMO architecture which provided running 2 seperate LSTM's from left and right and performing shallow concatenation which can also be done using keras Bidirectional wrapper.\n",
    "    Bert on the other hand computes dependency of each word with every other word in sentence by performing \"self attention\" . Attention mechanism makes transformer NLP's deeply bidirectional as the neural network is able to capture dependencies occuring far later in sentences. \n",
    "    \n",
    "BERT requires a pre-training task for capturing dependencies(or understanding the language basics) based on thier position or occurance in sentence. Transformer models are pre-trained on huge datasets for creating language understanding then are fine-tuned on a down stream task for classification , parts of speech tagging etc.\n",
    "When working with newer or different type of data as multilingual or codemixed we may need to train a BERT model from scratch we'll see how to achieve it in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "on2YnFGFohi0"
   },
   "source": [
    "### Training tokenizer for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cTg1IpTowBJ"
   },
   "outputs": [],
   "source": [
    "# install required dependencies for transformers and dataset\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_MqjnXrohi2"
   },
   "outputs": [],
   "source": [
    "''' The dataset used in this notebook is part of codalabs competition and can be found\n",
    "here : https://competitions.codalab.org/competitions/31146 '''\n",
    "# for creating bert vocabulary\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "# Initialize an empty BERT tokenizer\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "  clean_text=False,\n",
    "  handle_chinese_chars=False,\n",
    "  strip_accents=False,\n",
    "  lowercase=False,\n",
    ")\n",
    "\n",
    "# prepare text files to train vocab on them\n",
    "files = ['OffensiveLanguage/Task1/tamil_offensive.txt','OffensiveLanguage/Task1/tamil_offensive1.txt']\n",
    "\n",
    "# train BERT tokenizer\n",
    "tokenizer.train(\n",
    "  files,\n",
    "  vocab_size=30000,\n",
    "  min_frequency=2,\n",
    "  show_progress=True,\n",
    "  special_tokens=['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]'],\n",
    "  limit_alphabet=1000,\n",
    "  wordpieces_prefix=\"##\"\n",
    ")\n",
    "# save the vocab\n",
    "tokenizer.save('OffensiveLanguage/Task1/tamil_offensive_bert.json', pretty=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P44XedaM0ll5"
   },
   "source": [
    "### Loading the Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWVgdMbxqX1a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "f=open(\"tamil_offensive_bert.json\")\n",
    "k=json.load(f)\n",
    "d=k[\"model\"][\"vocab\"] # this is a dictionary mapping of vocabulary\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIYZAYRIol8g"
   },
   "outputs": [],
   "source": [
    "from tokenizers.implementations import BertWordPieceTokenizer\n",
    "from tokenizers.processors import BertProcessing, TemplateProcessing\n",
    "# create a Bert tokenizer object and pass the vocabulary we made above\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    d,lowercase=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQAfIkfArGi6"
   },
   "outputs": [],
   "source": [
    "#initialize tokenizer post processing function with bert's processor \n",
    "# Note : BertProcessing takes 2 arguments the seprator token its id from our vocab and cls token and its id\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"[SEP]\", tokenizer.token_to_id(\"[SEP]\")),\n",
    "    (\"[CLS]\", tokenizer.token_to_id(\"[CLS]\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BSumUmWr57T",
    "outputId": "ffe71b38-9ae9-4697-cf55-920922c4836c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'தலைவா',\n",
       " 'STR',\n",
       " 'இதுக்கு',\n",
       " '##தான்',\n",
       " 'கத',\n",
       " '##ுர',\n",
       " '##ுந்த',\n",
       " '##ோம்',\n",
       " 'மாஸ்',\n",
       " 'தலைவா',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer in action\n",
    "# here we're testing our tokenizer which has mixed languages namely tamil and english \n",
    "tokenizer.encode(\"தலைவா STR இதுக்குதான் கதுருந்தோம் மாஸ் தலைவா\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hf0ITimW7u08",
    "outputId": "d253b474-840d-4aea-bbfa-e3e58dbffd28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for cuda availability\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwTGADsn0zXA"
   },
   "source": [
    "<h2 style=\"text-align:center\">Creating model from a BERT configuration</h2>\n",
    "<p>Below is configuration table provided by google for different BERT configurations</p>\n",
    "We'll be training models on tiny bert and mini bert as they train much faster and would be more than enough for this dataset\n",
    "\n",
    "|   |H=128|H=256|H=512|H=768|\n",
    "|---|:---:|:---:|:---:|:---:|\n",
    "| **L=2**  |**2/128 (BERT-Tiny)**|2/256|2/512]|2/768|\n",
    "| **L=4**  |4/128|**4/256 (BERT-Mini)**|**4/512 (BERT-Small)**|4/768|\n",
    "| **L=6**  |6/128|6/256|6/512|6/768|\n",
    "| **L=8**  |8/128|8/256|**8/512 (BERT-Medium)**|8/768|\n",
    "| **L=10** |10/128|10/256|10/512|10/768|\n",
    "| **L=12** |12/128|12/256|12/512|**12/768 (BERT-Base)**|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Sm1Xzk7psOnN"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig\n",
    "# max_position_embeddings is often referred to as A and is equal to our max sentence length\n",
    "\n",
    "#tiny_bert=BertConfig(hidden_size=128,num_attention_heads=2,max_position_embeddings=128) # perf 80.66%\n",
    "#mini_bert=BertConfig(hidden_size=128,num_attention_heads=4,max_position_embeddings=128) # perf 80.38%\n",
    "tiny_bert=BertConfig(hidden_size=256,num_attention_heads=2,max_position_embeddings=128) # 81.2 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "18-MxdXSvq4v"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "tokenizer=BertTokenizerFast(\"tamil_offensive_bert.json\",tokenizer_file=\"tamil_offensive_bert.json\",do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_Wq3VeH_-Gx"
   },
   "source": [
    "## Create a model for BERT pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "N1Fd37jdxVcY"
   },
   "outputs": [],
   "source": [
    "# In original paper BERT models were pre trained on 2 tasks namely Masked language model and next sentence prediction\n",
    "# here we'll train model using maskedLM only\n",
    "from transformers import BertForMaskedLM #BertForPreTraining,BertForMaskedLM\n",
    "model=BertForMaskedLM(config=tiny_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgDjNPkxxjEx",
    "outputId": "a9ee608b-1f80-4206-ac1c-631c7cc3b3f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30028858"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of paramenters in our model \n",
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H24LYT3KxoWa"
   },
   "outputs": [],
   "source": [
    "from transformers import LineByLineTextDataset\n",
    "# creating input pipeline for our model\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"tamil_offensive.txt\",\n",
    "    block_size=128, #must be same as number of positional embeddings in bert \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "B0jQ4KcR-Bxb"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "# Initialize data collator which tokenizes and pre-processes data in our input pipeline\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcYgJ2Xq-C-w",
    "outputId": "aacde0d0-54a4-4bee-88ef-6ae7a9753748"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "# initilize trainer with training arguments \n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"task1/tamilBERT\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=20,\n",
    "    per_gpu_train_batch_size=64,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=3,\n",
    "    prediction_loss_only=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "yzR3LWXf-QLo",
    "outputId": "cb241029-d6a5-4ebc-9720-2ca5914125b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "***** Running training *****\n",
      "  Num examples = 6534\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2060\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2060' max='2060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2060/2060 13:52, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.097300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.354100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.083700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2060, training_loss=7.4172653050098605, metrics={'train_runtime': 833.0329, 'train_samples_per_second': 156.873, 'train_steps_per_second': 2.473, 'total_flos': 2212364461953096.0, 'train_loss': 7.4172653050098605, 'epoch': 20.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train() #begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozA_XBB9-Y-X",
    "outputId": "eb2cb20e-af8d-452f-ceb9-48eb8226bd36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to task1/tamilBERT\n",
      "Configuration saved in task1/tamilBERT/config.json\n",
      "Model weights saved in task1/tamilBERT/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"task1/tamilBERT\") #save model for fine-tuning on down stream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZs2KJ72Nid5"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "# 'test':['tam_offesive_withoutlabels_test.tsv']\n",
    "train_dataset=load_dataset('csv',data_files={'train':['train.csv']},split='train[:70%]')\n",
    "eval_dataset=load_dataset('csv',data_files={'train':['train.csv']},split='train[70%:]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GdDAqCx7VW83",
    "outputId": "35f646d9-627c-44df-a369-c0b6337977da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'tam1',\n",
       " 'label': 0,\n",
       " 'text': 'திருமலை நாயக்கர் பேரவை சார்பாக படம் வெற்றி பெற வாழ்த்துக்கள்'}"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gpqQ4YWOGgQ"
   },
   "outputs": [],
   "source": [
    "# apply pre processing on dataset here\n",
    "def tokenize_dataset(data):\n",
    "    return tokenizer(data[\"text\"],padding=\"max_length\",max_length=22,truncation=True)\n",
    "\n",
    "train_dataset=train_dataset.map(tokenize_dataset,batched=True)\n",
    "eval_dataset=eval_dataset.map(tokenize_dataset,batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WKD9y8tf50L"
   },
   "outputs": [],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brHR5ghPANvu"
   },
   "source": [
    "### Fine tune previously trained MLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUJCyRg8-gpH",
    "outputId": "85309cb6-abc3-499b-c465-6f3a1f07f7ef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file task1/tamilBERT/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 128,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 2,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file task1/tamilBERT/pytorch_model.bin\n",
      "Some weights of the model checkpoint at task1/tamilBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at task1/tamilBERT and are newly initialized: ['classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model=AutoModelForSequenceClassification.from_pretrained(\"task1/tamilBERT\",num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "bP_vJyukLWpX",
    "outputId": "dfa57356-0b48-490b-94ff-b407111ee5ad"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 4116\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1545\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1545' max='1545' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1545/1545 01:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.350300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.266800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1000\n",
      "Configuration saved in test_trainer/checkpoint-1000/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to test_trainer/checkpoint-1500\n",
      "Configuration saved in test_trainer/checkpoint-1500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-1500/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1545, training_loss=0.35003116076818175, metrics={'train_runtime': 73.0205, 'train_samples_per_second': 169.103, 'train_steps_per_second': 21.158, 'total_flos': 48895371046368.0, 'train_loss': 0.35003116076818175, 'epoch': 3.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_args=TrainingArguments(\"test_trainer\")\n",
    "\n",
    "trainer=Trainer(model=model,\n",
    "                args=train_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "6d4b54cb92ad407c9b2d8afdc53d02d9",
      "8988ddb05c73438cb39f761a0fb5cc6b",
      "7c09e7a53d9443e3919d7f345a811e53",
      "9ffb1b6018f04037b6d7e8e6f5977b69",
      "880848884523467ebf80c49fe6f3d5a6",
      "5b7317419b914d6eb20acdbb2341512e",
      "aa72b509a37843c797f332b71da99bc2",
      "0a6fcc997a9047c69cb6f115916f7a70"
     ]
    },
    "id": "cU_7ooLsMCYP",
    "outputId": "08765652-6c72-4390-bc5a-a765261887f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4b54cb92ad407c9b2d8afdc53d02d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1362.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# here we'll create a function that'll compute metrics and output performance of our trained model from evaluator\n",
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "metric=load_metric(\"accuracy\")\n",
    "def compute_metrics(pred):\n",
    "    logits,labels=pred\n",
    "    model_preds=np.argmax(logits,axis=-1)\n",
    "    return metric.compute(predictions=model_preds,references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "YqZdaOHUNGaO",
    "outputId": "84ff92b6-579f-4666-84d3-a0afc1b5926b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1764\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='221' max='221' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [221/221 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_accuracy': 0.8117913832199547,\n",
       " 'eval_loss': 0.6345648169517517,\n",
       " 'eval_runtime': 2.3954,\n",
       " 'eval_samples_per_second': 736.404,\n",
       " 'eval_steps_per_second': 92.259}"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# intialize trainer and evaluate\n",
    "trainer=Trainer(model=model,\n",
    "                args=train_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=eval_dataset,\n",
    "                compute_metrics=compute_metrics)\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "v-b3cSOsAXxJ"
   },
   "outputs": [],
   "source": [
    "!rm -r test_trainer"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a6fcc997a9047c69cb6f115916f7a70": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b7317419b914d6eb20acdbb2341512e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d4b54cb92ad407c9b2d8afdc53d02d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7c09e7a53d9443e3919d7f345a811e53",
       "IPY_MODEL_9ffb1b6018f04037b6d7e8e6f5977b69"
      ],
      "layout": "IPY_MODEL_8988ddb05c73438cb39f761a0fb5cc6b"
     }
    },
    "7c09e7a53d9443e3919d7f345a811e53": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b7317419b914d6eb20acdbb2341512e",
      "max": 1362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_880848884523467ebf80c49fe6f3d5a6",
      "value": 1362
     }
    },
    "880848884523467ebf80c49fe6f3d5a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8988ddb05c73438cb39f761a0fb5cc6b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ffb1b6018f04037b6d7e8e6f5977b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a6fcc997a9047c69cb6f115916f7a70",
      "placeholder": "​",
      "style": "IPY_MODEL_aa72b509a37843c797f332b71da99bc2",
      "value": " 2.92k/? [01:28&lt;00:00, 33.1B/s]"
     }
    },
    "aa72b509a37843c797f332b71da99bc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
